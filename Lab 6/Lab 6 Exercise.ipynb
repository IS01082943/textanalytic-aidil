{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4425f7-afae-405e-bee1-33ba03361bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  \\\n",
      "0  The product arrived on time. Packaging was gre...   \n",
      "1           THIS PRODUCT IS JUST AMAZING! I LOVE IT.   \n",
      "2  I bought this phone for $799, and it has a 120...   \n",
      "3  Wow!!! This product is awesome... but a bit ex...   \n",
      "4                The laptop works perfectly fine.      \n",
      "\n",
      "                                          lowercased  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                        urls_removed  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                        html_removed  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                      emojis_removed  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                     slangs_replaced  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                               contractions_replaced  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                punctuations_removed  \\\n",
      "0  the product arrived on time packaging was grea...   \n",
      "1             this product is just amazing i love it   \n",
      "2  i bought this phone for 799 and it has a 120hz...   \n",
      "3    wow this product is awesome but a bit expensive   \n",
      "4                 the laptop works perfectly fine      \n",
      "\n",
      "                                     numbers_removed  \\\n",
      "0  the product arrived on time packaging was grea...   \n",
      "1             this product is just amazing i love it   \n",
      "2  i bought this phone for  and it has a hz displ...   \n",
      "3    wow this product is awesome but a bit expensive   \n",
      "4                 the laptop works perfectly fine      \n",
      "\n",
      "                                  spelling_corrected  \\\n",
      "0  the product arrived on time packaging was grea...   \n",
      "1             this product is just amazing i love it   \n",
      "2  i bought this phone for  and it has a hz displ...   \n",
      "3    wow this product is awesome but a bit expensive   \n",
      "4                 the laptop works perfectly fine      \n",
      "\n",
      "                                   stopwords_removed  \\\n",
      "0  product arrived time packaging great quality a...   \n",
      "1                               product amazing love   \n",
      "2              bought phone hz display totally worth   \n",
      "3                  wow product awesome bit expensive   \n",
      "4                        laptop works perfectly fine   \n",
      "\n",
      "                                  stemmed_words  \\\n",
      "0  product arriv time packag great qualiti amaz   \n",
      "1                             product amaz love   \n",
      "2           bought phone hz display total worth   \n",
      "3                 wow product awesom bit expens   \n",
      "4                    laptop work perfectli fine   \n",
      "\n",
      "                                          lemmatized  \\\n",
      "0  product arrive time packaging great quality am...   \n",
      "1                                 product amaze love   \n",
      "2                 buy phone hz display totally worth   \n",
      "3                  wow product awesome bit expensive   \n",
      "4                         laptop work perfectly fine   \n",
      "\n",
      "                                           tokenized  \n",
      "0  ['product', 'arrive', 'time', 'packaging', 'gr...  \n",
      "1                       ['product', 'amaze', 'love']  \n",
      "2  ['buy', 'phone', 'hz', 'display', 'totally', '...  \n",
      "3  ['wow', 'product', 'awesome', 'bit', 'expensive']  \n",
      "4            ['laptop', 'work', 'perfectly', 'fine']  \n",
      "Review                   0\n",
      "lowercased               0\n",
      "urls_removed             0\n",
      "html_removed             0\n",
      "emojis_removed           0\n",
      "slangs_replaced          0\n",
      "contractions_replaced    0\n",
      "punctuations_removed     0\n",
      "numbers_removed          0\n",
      "spelling_corrected       0\n",
      "stopwords_removed        0\n",
      "stemmed_words            0\n",
      "lemmatized               0\n",
      "tokenized                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m tfidf_vect \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m     19\u001b[0m X \u001b[38;5;241m=\u001b[39m tfidf_vect\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemmatized\u001b[39m\u001b[38;5;124m'\u001b[39m])  \n\u001b[1;32m---> 20\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n\u001b[0;32m     23\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Processed_Reviews.csv\")  \n",
    "print(df.head())\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X = tfidf_vect.fit_transform(df['lemmatized'])  \n",
    "y = df['label']  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(cm, classes=['Negative', 'Positive'], title='Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2ae1e-9cb8-4362-8cf4-fb0b787364d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
